{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43979182-e345-4d24-9ba2-1f4523112c14",
   "metadata": {},
   "source": [
    "# Executing and analysing the main BTM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad53b984-058d-47dc-9fc5-9c5dcdd542f5",
   "metadata": {},
   "source": [
    "Having prepared the data and selected our model, we will run the final model and save the outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81aed8b0-c5e8-46a4-8d71-66d9bf3339d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import bitermplus as btm\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "# Number of topics\n",
    "ntopics = 19 # From narrow search (02/02a)\n",
    "\n",
    "# Run type (some details about this run) used to label output\n",
    "run_type = \"NONUMBERS_DEDUPED_AdStpwds\"\n",
    "\n",
    "# Output folder\n",
    "output_folder = \"/Users/jamiesanders/Desktop/PrintHistProj/output/results/\" # End in /"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74730f63-e6d2-4024-b850-96e0b3c96aba",
   "metadata": {},
   "source": [
    "## Prepare data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a303fab-1ecb-4296-89de-a23941092897",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load processed data\n",
    "filtered_data = pd.read_csv(\"/Users/jamiesanders/Desktop/PrintHistProj/data/processed/estc_btm_prepped.csv\")\n",
    "\n",
    "# prepare BTM files\n",
    "texts = filtered_data[\"clean_title\"].to_list()\n",
    "X, vocabulary, vocab_dict = btm.get_words_freqs(filtered_data[\"clean_title\"])\n",
    "docs_vec = btm.get_vectorized_docs(texts, vocabulary)\n",
    "biterms = btm.get_biterms(docs_vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de60728-07a3-4648-bdf9-39c645e3435a",
   "metadata": {},
   "source": [
    "## Run chosen model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d45e7b36-804d-4edb-affa-f9c2c06918d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 600/600 [34:36<00:00,  3.46s/it]\n",
      "100%|██████████████████████████████████| 94690/94690 [00:02<00:00, 34782.63it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1.38730805e-01, 3.11873431e-02, 1.79810720e-01, ...,\n",
       "        5.59543005e-02, 6.44385594e-02, 1.19650092e-02],\n",
       "       [6.95159611e-01, 4.62764515e-02, 2.92878767e-03, ...,\n",
       "        4.58391991e-03, 3.45943121e-03, 9.56231569e-04],\n",
       "       [2.15093172e-02, 2.89835766e-01, 1.72206031e-02, ...,\n",
       "        2.65587258e-03, 5.49968573e-02, 1.35081717e-04],\n",
       "       ...,\n",
       "       [4.78529059e-02, 2.60241415e-03, 8.83031892e-03, ...,\n",
       "        8.37687389e-03, 4.40198125e-03, 9.20453248e-03],\n",
       "       [8.16216739e-02, 1.30081764e-01, 2.19133711e-02, ...,\n",
       "        1.22861171e-02, 1.03983908e-01, 3.58054423e-03],\n",
       "       [2.59215774e-03, 1.11068055e-01, 1.35624265e-02, ...,\n",
       "        3.09698867e-02, 3.45043666e-02, 2.57143087e-02]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = btm.BTM(\n",
    "    n_dw = X, # Documents vs words frequency matrix\n",
    "    vocabulary = vocabulary, # List of all words\n",
    "    seed = 931, # Random state seed, set for repeatability\n",
    "    T = ntopics, # Number of topics\n",
    "    alpha = 50/ntopics, # Symmetric dirichlet prior probability of a topic P(z) (literature default)\n",
    "    beta = 0.01 # Symmetric dirichlet prior probability of a word given the topic P(w|z) (literature default)\n",
    ")\n",
    "\n",
    "model.fit_transform(docs_vec, biterms, iterations=600, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e14fd421-eae3-4fa8-90ec-0330951a1320",
   "metadata": {},
   "source": [
    "## Saving output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4370239d-085e-414b-b1ad-1c7b889fc541",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prefix for saving\n",
    "prefix = output_folder + \"BTM\" + str(ntopics) + \"_\" + run_type + \"__\"\n",
    "\n",
    "# Document Topic Probability Matrix\n",
    "topic_doc_mat = pd.DataFrame(model.matrix_topics_docs_,)\n",
    "topic_doc_mat.to_csv(prefix + \"TOPIC_DOC_MAT.csv\", index=False)\n",
    "\n",
    "# Most characteristic words for each topic\n",
    "btm.get_top_topic_words(model).to_csv(prefix + \"TOP_WORDS.csv\", index=False)\n",
    "\n",
    "# Built in function for top docs isn't working, so built it myself (horribly inefficient, please don't judge me)\n",
    "doc_topic_mat = topic_doc_mat.transpose()\n",
    "results_joined = filtered_data.reset_index(drop=True).join(doc_topic_mat)\n",
    "\n",
    "top_docs = pd.DataFrame()\n",
    "for col in range(0,ntopics):\n",
    "    top_titles = results_joined.sort_values(col, axis = 0, ascending = False)['title'][0:20]\n",
    "    top_docs[col] = top_titles.reset_index(drop=True)\n",
    "    top_docs = top_docs.reset_index(drop=True)\n",
    "    \n",
    "top_docs.to_csv(prefix + \"TOP_DOCS.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
